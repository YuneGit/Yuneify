# Import necessary libraries
import reapy
import time
import openai
import random
from pydantic import BaseModel  # Library for data validation and parsing
from openai import OpenAI
import json  # For working with JSON data
import sys  # For system-specific parameters and functions
from PySide6.QtWidgets import (QApplication, QWidget, QVBoxLayout, QHBoxLayout, QGridLayout,
                              QLabel, QPushButton, QComboBox, QLineEdit, QGroupBox,
                              QSlider, QStatusBar)
from PySide6.QtGui import QIcon, QFont
from PySide6.QtCore import Qt
from PySide6.QtCore import QTimer, Qt
from PySide6.QtGui import QIcon, QFont
from modules.styles import apply_dark_theme  # Import the stylesheet function
from modules.AI_func.ai_models import MidiNote, OrchestrationPlan
from modules.AI_func.ai_models import get_model_handler
from typing import Dict


# Define a Pydantic model to represent a MIDI note
# This model enforces the structure of a MIDI note object
class MidiOrchestrationResponse(BaseModel):
    gpt_notes: list[MidiNote]  # List of MIDI notes generated by GPT

class AIOrchestrationStyleSelector(QWidget):
    def __init__(self):
        super().__init__()
        self.initUI()
        self.midi_orchestrator = AIMidiOrchestrator()  # Initialize orchestrator

    def initUI(self):
        self.setWindowTitle('AI Orchestration Style')
        self.setMinimumSize(350, 300)
        
        apply_dark_theme(self)
        layout = QVBoxLayout()
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(15)

        # Style Selection Group
        style_group = QGroupBox("Orchestration Style Presets")
        style_layout = QGridLayout()
        style_layout.setVerticalSpacing(10)
        style_layout.setHorizontalSpacing(15)
        
        # Organized style categories
        self.style_combo = QComboBox()
        self.style_combo.addItems([
            'Cinematic Epic', 'Chamber Ensemble', 'Electronic Hybrid',
            'Baroque', 'Romantic Era', 'Modern Minimalist',
            'Jazz Big Band', 'Rock/Pop Arrangement', 'Video Game Scoring'
        ])
        self.style_combo.setCurrentIndex(-1)
        self.style_combo.setToolTip("Select a pre-configured orchestration style")
        
        # Quick access buttons
        self.favorite_btn = QPushButton("â­")
        self.favorite_btn.setFixedSize(30, 30)
        self.favorite_btn.setToolTip("Save as favorite")
        
        self.recent_btn = QPushButton("ðŸ•’") 
        self.recent_btn.setFixedSize(30, 30)
        self.recent_btn.setToolTip("Recent styles")

        style_layout.addWidget(QLabel("Preset Style:"), 0, 0)
        style_layout.addWidget(self.style_combo, 0, 1, 1, 2)
        style_layout.addWidget(self.favorite_btn, 0, 3)
        style_layout.addWidget(self.recent_btn, 0, 4)
        
        # Advanced parameters
        self.detail_slider = QSlider(Qt.Horizontal)
        self.detail_slider.setRange(1, 5)
        self.detail_slider.setValue(3)
        self.detail_slider.setTickInterval(1)
        self.detail_slider.setToolTip("AI creativity/detail level")
        
        style_layout.addWidget(QLabel("Detail Level:"), 1, 0)
        style_layout.addWidget(self.detail_slider, 1, 1, 1, 4)
        
        style_group.setLayout(style_layout)
        layout.addWidget(style_group)

        # Custom Instructions
        prompt_group = QGroupBox("Custom Instructions")
        prompt_layout = QVBoxLayout()
        self.prompt_input = QLineEdit()
        self.prompt_input.setPlaceholderText("Describe the desired orchestration...")
        self.prompt_input.setClearButtonEnabled(True)
        prompt_layout.addWidget(self.prompt_input)
        
        # Example prompts button
        self.examples_btn = QPushButton("Show Examples â†’")
        self.examples_btn.setStyleSheet("QPushButton { border: none; color: #4FC3F7; }")
        self.examples_btn.clicked.connect(self.show_prompt_examples)
        prompt_layout.addWidget(self.examples_btn)
        
        prompt_group.setLayout(prompt_layout)
        layout.addWidget(prompt_group)

        # Action Section
        action_layout = QHBoxLayout()
        self.send_button = QPushButton("Generate Orchestration")
        self.send_button.setIcon(QIcon.fromTheme("document-send"))
        self.send_button.setStyleSheet("""
            QPushButton {
                background: #2E7D32;
                padding: 8px;
                border-radius: 4px;
                font-weight: bold;
            }
            QPushButton:hover { background: #388E3C; }
        """)
        self.send_button.clicked.connect(self.on_send_to_gpt)
        
        self.stop_button = QPushButton("Stop")
        self.stop_button.setStyleSheet("QPushButton { background: #C62828; }")
        
        action_layout.addWidget(self.stop_button)
        action_layout.addWidget(self.send_button)
        layout.addLayout(action_layout)

        # Status Bar
        self.status_bar = QStatusBar()
        self.status_bar.setFont(QFont("Segoe UI", 9))
        layout.addWidget(self.status_bar)

        self.setLayout(layout)

    def on_send_to_gpt(self):
        selected_style = self.style_combo.currentText()
        custom_instructions = self.prompt_input.text()
        print(f"Selected style: {selected_style}")
        
        # Replace feedback_label with status_bar
        self.status_bar.showMessage(f"Processing '{selected_style}'...", 3000)

        # Update the orchestrator with the selected style and custom instructions
        self.midi_orchestrator.style = selected_style
        self.midi_orchestrator.custom_instructions = custom_instructions
        self.midi_orchestrator.run()

    def show_prompt_examples(self):
        examples = [
            "Bright brass fanfares with woodwind countermelodies",
            "Subtle string pads with harp arpeggios",
            "Percussive rhythmic patterns with synth bass",
            "Woodwind-led chamber ensemble texture",
            "Full orchestral tutti with crashing cymbals"
        ]
        self.prompt_input.setText(random.choice(examples))
        self.status_bar.showMessage("Example prompt inserted!", 3000)

    def get_selected_style(self):
        return self.style_combo.currentText()

# Class to handle MIDI pitch transposition and orchestration
class AIMidiOrchestrator:
    def __init__(self, style='Default', custom_instructions='', model_name='openai'):
        with reapy.inside_reaper():
            self.project = reapy.Project()
        self.style = style
        self.custom_instructions = custom_instructions
        self.model = get_model_handler(model_name)  # Use model handler

    # Main method to run the MIDI transposition and orchestration
    def run(self):
        with reapy.inside_reaper():
            item = self.project.get_selected_item(0)
            if not item:
                print("No selected item.")
                return

            take = item.active_take
            if not take:
                print("No active take.")
                return

            notes = take.notes
            if not notes:
                print("No MIDI notes.")
                return

            print(f"Found {len(notes)} notes.")
            note_infos = [note.infos for note in notes]

            orchestrated_notes = self.send_notes_to_ai(note_infos)
            self.import_orchestrated_notes(take, orchestrated_notes)

    def send_notes_to_ai(self, note_infos):
        """Send MIDI notes to AI for orchestration"""
        system_prompt = f"""
        You are an orchestration expert. Convert this MIDI input into a full orchestral score.
        Respond in this EXACT structure:
        {{
            "orchestral_score": {{
                "sections": [
                    {{
                        "instrument": "Violin",
                        "channel": 1,
                        "notes": [
                            {{
                                "start": 0.0,
                                "end": 1.0,
                                "pitch": 60,
                                "velocity": 100,
                                "articulation": "staccato"
                            }}
                        ]
                    }}
                ],
                "dynamics": {{
                    "1": "pp"  # Channel number as key
                }},
                "articulation": "general articulation style"
            }}
        }}
        """
        
        try:
            response = self.model.generate_text(
                system_prompt=system_prompt,
                user_prompt=f"{self.style} style. {self.custom_instructions}",
                midi_data=note_infos,
                temperature=0.7,
                max_tokens=1500
            )
            print("Raw AI Response:", response)
            
            parsed_response = json.loads(response)
            score_data = parsed_response["orchestral_score"]
            
            # Process sections into channels and notes
            instruments = {}
            all_notes = []
            
            for section in score_data["sections"]:
                channel = section.get("channel", len(instruments)+1)
                instruments[channel] = section["instrument"]
                all_notes.extend(section["notes"])
            
            # Handle dynamics parsing safely
            dynamics = {}
            if "dynamics" in score_data:
                for key, value in score_data["dynamics"].items():
                    if key.isdigit():  # Only process numeric channel keys
                        dynamics[int(key)] = value
                    else:
                        print(f"Skipping invalid dynamics channel key: {key}")

            return OrchestrationPlan(
                instruments=instruments,
                notes=all_notes,
                dynamics=dynamics,
                articulation=score_data.get("articulation", "default")
            )
        except Exception as e:
            print(f"Orchestration error: {str(e)}")
            return None

    def import_orchestrated_notes(self, take, plan: OrchestrationPlan):
        """Import orchestrated notes with instrument mapping"""
        with reapy.inside_reaper():
            # Get reference to the original track
            original_track = take.track
            
            # Create new tracks for each instrument
            instrument_tracks = {}
            for channel, instrument in plan.instruments.items():
                # Create new track with instrument plugin
                instrument_track = self.add_track_with_plugin(instrument)
                instrument_tracks[channel] = instrument_track
                
                # Create new MIDI item on the track
                item = instrument_track.add_midi_item()
                new_take = item.active_take

                # Add notes to the new track's take
                for note in (n for n in plan.notes if n.get('channel') == channel):
                    new_take.add_note(
                        start=new_take.time_to_ppq(note.start),
                        end=new_take.time_to_ppq(note.end),
                        pitch=note.pitch,
                        velocity=note.velocity,
                        channel=0,  # Use channel 0 for new tracks
                        unit="ppq",
                        sort=True
                    )

            # Delete original MIDI item if empty
            if not take.notes:
                take.item.delete()

    def add_track_with_plugin(self, plugin_name):
        """Create new track with instrument plugin"""
        track = self.project.add_track(name=plugin_name)
        try:
            # Attempt to add the plugin, but continue even if it fails
            track.add_fx(plugin_name)
        except Exception as e:
            print(f"Couldn't load plugin '{plugin_name}'. Creating empty track. Error: {str(e)}")
        return track

    def get_midi_data(self) -> Dict:
        """Fetch MIDI data from selected item with validation."""
        item = self.project.get_selected_item(0)
        if not item:
            raise ValueError("No MIDI item selected")
        
        take = item.active_take
        if not take:
            raise ValueError("No active take")
            
        return {
            "notes": [note.infos for note in take.notes],
            "tempo": self.project.bpm,
            "time_signature": self.project.time_signature
        }

# Entry point of the script
if __name__ == "__main__":
    app = QApplication([])
    style_selector = AIOrchestrationStyleSelector()
    style_selector.show()
    sys.exit(app.exec())
